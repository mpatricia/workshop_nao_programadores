{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - Workshop de Modelagem Preditiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informações úteis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para rodar os códigos no jupyter notebook, clicar na célula desejada e usar o atalho Shift+Enter (roda e vai para a próxima célula) ou Ctrl+Enter (roda).\n",
    "\n",
    "O material necessário para esse notebook está todo disponível no repositório: https://analytics.fontes.intranet.bb.com.br/templates/workshop-modelagem-preditiva.git\n",
    "\n",
    "Para copiar o conteúdo desse repositório no seu projeto na Plataforma Analítica:\n",
    "1. Abra o terminal da Plataforma Analítica\n",
    "2. Execute o comando abaixo no terminal da Plataforma\n",
    "\n",
    "    git clone https://analytics.fontes.intranet.bb.com.br/templates/workshop-modelagem-preditiva.git\n",
    "\n",
    "Dica: Os atalhos para copiar e colar no terminal da Plataformas são: Ctrl+Insert (copiar) e Shift+Insert (colar).\n",
    "\n",
    "O notebook está organizado conforme as etapas do modelo CRISP-DM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar Ambiente e Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consutar bibliotecas e versões instaladas na Plataforma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook serão usadas algumas das bibliotecas mais comumente utilizadas em projetos de análise de dados. \n",
    "\n",
    "É preciso instalar as bibliotecas usadas que não estiverem listadas, o comando abaixo instala as bibliotecas seaborn e sklearn:\n",
    "\n",
    "    !pip install seaborn sklearn --user\n",
    "\n",
    "Após instalar bibliotecas recomenda-se reiniciar o kernel clicando no menu Kernel, opção Restart Kernel...\n",
    "\n",
    "Com as bibliotecas necessárias já instaladas, é preciso carregá-las conforme código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # manipulação numérica\n",
    "import pandas as pd # manipulação de dataframes (datasets)\n",
    "\n",
    "import matplotlib.pyplot as plt # visualização de gráficos\n",
    "import seaborn as sns # visualização de gráficos\n",
    "\n",
    "from sklearn.impute import SimpleImputer # tratamento de valores ausentes\n",
    "from sklearn.preprocessing import OneHotEncoder # tratamento de variáveis categóricas\n",
    "from sklearn.compose import ColumnTransformer # definir tratamento para cada lista de variáveis\n",
    "\n",
    "from sklearn.pipeline import Pipeline # definir sequência de cálculos do algoritmo de aprendizagem\n",
    "from sklearn.model_selection import train_test_split # separar dados de treino e teste\n",
    "from sklearn.model_selection import cross_val_score # validação cruzada\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score  # métricas de performance do modelo\n",
    "from sklearn.model_selection import GridSearchCV # otimização de hiperparâmetros\n",
    "\n",
    "# Algoritmos de aprendizagem\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import discriminant_analysis\n",
    "\n",
    "from joblib import dump, load # salvar e carregar modelo\n",
    "\n",
    "# Omitir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendimento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e pré-visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./UCI_Credit_Card_treino.csv', sep=',', decimal='.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantidade de observações e colunas:', df.shape)\n",
    "for v in df.columns:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear algumas colunas\n",
    "df = df.rename(columns={'default.payment.next.month': 'DEFAULT', \n",
    "                        'PAY_0': 'PAY_1'})\n",
    "\n",
    "# Excluir coluna ID, pois não será utilizada para aprendizado do modelo\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação das variáveis por tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis Numéricas\n",
    "vnum = ['LIMIT_BAL', 'AGE', \n",
    "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "        'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "\n",
    "# Variáveis Categóricas\n",
    "vcat = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "# Variável target\n",
    "vtgt = ['DEFAULT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variável Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('DEFAULT', data=df, palette=\"Blues\")\n",
    "pct_default = round(df['DEFAULT'].sum()/len(df)*100)\n",
    "plt.annotate(str(pct_default)+\" %\", xy=(0.7, 15000), xytext=(0.9, 8000), size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões:\n",
    "* A variável target é do tipo categórica e possui 2 categorias: 0 = cliente com pagamento em dia, 1 = cliente em descumprimento. Nesse caso, estamos diante de um problema de aprendizado supervisionado do tipo classificação.\n",
    "* O percentual de clientes em descumprimento é menor que o de clientes com pagamento em dia. Quando alguma categoria é muito rara, menor que 5%, é recomendado realizar o balanceamento de classes. Nesse caso, não será necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preditores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[vnum].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões:\n",
    "* LIMIT_BAL: clientes possuem limites entre 10 mil e 1 milhão.\n",
    "* AGE: clientes possuem idade entre 21 e 79 anos.\n",
    "* BILL_AMT: alguns clientes possuem faturas negativas, o que pode ser explicado por ressarcimentos, mas é ideal verificar. \n",
    "* PAY_AMT: o valor pago no mês anterior é sempre positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7, 2, figsize = (20, 25), facecolor='white')  \n",
    "for axs, v in zip(axs.flatten(), vnum):\n",
    "    ax = sns.boxplot(x=v, y=\"DEFAULT\", data=df, orient='h', palette=\"Blues\", ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões:\n",
    "* LIMIT_BAL: clientes que ficam em default apresentam limites menores.\n",
    "* AGE: a idade não parece ter relação com a target.\n",
    "* BILL_AMT: clientes que ficam em default apresentam valores sensivelmente menores de fatura. \n",
    "* PAY_AMT: clientes que ficam em default apresentam pagamentos menores de fatura. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preditores Categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize = (20,10), facecolor='white')\n",
    "fig.suptitle('% DE CADA CATEGORIA')\n",
    "for ax, v in zip(axs.flatten(), vcat):\n",
    "    tab = pd.DataFrame(df[v].value_counts()/len(df))\n",
    "    tab['x'] = tab.index\n",
    "    ax = sns.barplot(data=tab, x='x', y=v, color='lightblue', ax=ax)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões:\n",
    "* SEX: a maioria dos clientes são mulheres (60%).\n",
    "* EDUCATION: a maioria dos clientes possui graduação (50%), pós-graduação (35%) e ensino médio (15%). Obs: a categoria 0 não foi citada no dicionário de dados.\n",
    "* MARRIAGE: a maioria dos clientes são solteiros (52%) seguido dos casados (45%). Obs: a categoria 0 não foi citada no dicionário.\n",
    "* PAY: a maioria dos clientes está usando o crédito rotativo (50%), seguido por pagamento ok (20%) e sem consumo (10%), os demais são categorias em atraso. Obs: a categoria 1 = atrasado 1 mês só aparece no mês mais recente, o ideal seria verificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize = (20,10), facecolor='white')\n",
    "fig.suptitle('% DEFAULT EM CADA CATEGORIA')\n",
    "for ax, v in zip(axs.flatten(), vcat):\n",
    "    tab = df[['DEFAULT', v]].groupby([v]).mean()\n",
    "    tab[v] = tab.index\n",
    "    ax = sns.barplot(data=tab, x=v, y='DEFAULT', color='lightblue', ax=ax)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões:\n",
    "* SEX: as mulheres apresentaram taxa de default ligeiramente menor que a dos homens, 20% e 24% respectivamente.\n",
    "* EDUCATION: os clientes cujo nível de instrução é outros ou desconhecido possuem menores taxas de default, seguido pelos clientes que possuem pós-graduação (18%).\n",
    "* MARRIAGE: a taxa de default entre casados e solteiros é muito próxima, o estado civil não parece ter influência na taxa de fault.\n",
    "* PAY: os clientes com faturas em atraso (categoria >= 2) apresentam as maiores taxas de default, o que já é esperado. Apesar de ser uma variável categórica, quanto mais próximo da categoria 8, maior a taxa de default, e quanto mais próximo da categoria -2, menor a taxa de default. Portanto, não será transformada em dummies e será utilizada como variável numérica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação das Variáveis após Entendimento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis Numéricas\n",
    "vnum = ['LIMIT_BAL', 'AGE', \n",
    "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "        'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
    "        'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "# Variáveis Categóricas\n",
    "vcat = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "\n",
    "# Variável Target\n",
    "vtgt = ['DEFAULT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Valores Ausentes/Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tratamento adequado depende de cada caso, alguns exemplos são:\n",
    "* Variáveis com alto percentual de missing (acima de 10%) pode ser considerada a exclusão do aprendizado.\n",
    "* Observações com alto percentual de missing (acima de 40%) pode ser considerada a exclusão do aprendizado. \n",
    "* Excluir observações com variável target missing nos dados de treino.\n",
    "* Em variáveis numéricas, pode-se substituir os valores ausentes pela média/mediana dos valores válidos.\n",
    "* Em variáveis categóricas, pode-se criar uma nova categoria para comportar os valores ausentes ou substituí-los pela categoria mais frequente.\n",
    "* Em alguns casos pode ser útil aplicar um modelo preditivo para preencher os missing com valor estimado a partir dos outros preditores preenchidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual de valores ausentes por variável\n",
    "pct_miss = 100*df.isnull().sum()/len(df)\n",
    "pct_miss[(-pct_miss).argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método de imputação para variáveis numéricas -> substituir pela mediana\n",
    "imp_num = SimpleImputer(missing_values=np.nan, strategy='median', add_indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar variáveis numéricas antes da imputação\n",
    "df[vnum].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar variáveis numéricas após imputação\n",
    "pd.DataFrame(imp_num.fit_transform(df[vnum])).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Preditores Categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, o tratamento adequado depende do caso, alguns exemplos:\n",
    "* Em variáveis com poucas categorias distintas, é comum criar variáveis indicadoras para cada categoria (dummies).\n",
    "* Em variáveis com muitas categorias distintas, 20 ou mais, pode ser considerado outros métodos como criar agrupamentos de categorias que sejam semelhantes em relação à taxa de default, ou usar a própria taxa de default de cada categoria em substituição ao label da categoria (target_encoder):\n",
    "\n",
    "        from category_encoders.target_encoder import TargetEncoder\n",
    "        tge = TargetEncoder(handle_unknown='value', drop_invariant=True, min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para criar variáveis indicadoras para cada categoria\n",
    "ohe = OneHotEncoder(handle_unknown='error', drop='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar variáveis antes do encoding\n",
    "df[vcat].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar variáveis após encoding\n",
    "pd.DataFrame(ohe.fit_transform(df[vcat]).toarray(), columns=ohe.get_feature_names(vcat)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir pré-processamento a ser aplicado a cada variável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo será consolidado os diversos tratamentos aplicados a cada conjunto de variáveis. Para as variáveis numéricas a necessidade de imputação pela média nos valores ausentes e para as variáveis categóricas a criação de variáveis indicadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[('vnum', imp_num, vnum),\n",
    "                                               ('vcat', ohe, vcat)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar dados de treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de treino será utilizada para treinamento e validação, enquando a base de teste será utilizada para avaliação do modelo, como uma forma de mensurar de forma independente do treinamento o qão bem o modelo irá performar nos novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis preditoras no objeto X\n",
    "X = df[vnum + vcat]\n",
    "\n",
    "# Variável Target no objeto y\n",
    "y = df[vtgt]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento dos Algoritmos de Aprendizagem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algoritmos = [\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.RandomForestClassifier(), \n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    linear_model.LogisticRegression(),\n",
    "    linear_model.RidgeClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for alg in algoritmos:\n",
    "    \n",
    "    print('Rodando algoritmo:', alg.__class__.__name__)\n",
    "    \n",
    "    # Pipeline - sequencia de passos de pré-processamento e treinamento do algoritmo de aprendizagem\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', alg)])\n",
    "    \n",
    "    # Mensurar métrica de performance roc_auc usando validação cruzada\n",
    "    measure_results = cross_val_score(my_pipeline, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    results.append({'Estimator':alg.__class__.__name__, 'Score médio':measure_results.mean()})\n",
    "    \n",
    "    print('AUC da Validação Cruzada:', round(measure_results.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão:\n",
    "\n",
    "O algoritmo de aprendizagem que apresentou melhor performance foi o GradientBoostingClassifier. A métrica escolhida para seleção do melhor modelo foi a área abaixo da curva ROC por ser uma medida adequada a problemas de classificação onde uma das categorias é mais rara que a outra, como é o caso do problema em análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização dos Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No etapa anterior, o treinamento dos algoritmos de aprendizagem foi realizado considerando os hiperparâmetros pré-definidos (default). Hiperparâmetros são parâmetros que controlam o treinamento do modelo. \n",
    "\n",
    "Cada algoritmo de aprendizagem possui seus hiperparâmetros específicos. Por exemplo, um dos hiperparâmetros do algoritmo GradientBoostingClassifier é a quantidade de classificadores (n_estimators) a ser adicionada. Portanto, o hiperparâmetro n_estimators controla como o modelo será treinado. Quanto menor o valor de n_estimators, maior a tendência de underfitting, quanto maior o valor de n_estimators, maior a tendência de overfitting. Então, como definir o valor ideal de n_estimators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessário preprocessar dados antes\n",
    "X_train_ = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Algoritmo a ser otimizado: KNN\n",
    "alg = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "# Definir valores de K a serem testados\n",
    "n_estimators = list(range(5,55,5))\n",
    "hiperparametros = dict(n_estimators=n_estimators)\n",
    "\n",
    "# Treinar modelo para os valores de K\n",
    "gs = GridSearchCV(alg, hiperparametros, cv=5, scoring='accuracy', return_train_score=True).fit(X_train_, y_train)\n",
    "\n",
    "# Gráfico com resultados\n",
    "plt.plot(n_estimators, gs.cv_results_['mean_test_score'], label=\"AUC Teste\")\n",
    "plt.plot(n_estimators, gs.cv_results_['mean_train_score'], label=\"AUC Treino\")\n",
    "leg = plt.legend(loc='lower right', ncol=1, shadow=True, fancybox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão:\n",
    "\n",
    "A partir de 10 estimadores a performance no teste da validação cruzada não tem mais ganho, apesar da performance no treino melhorar adicionando mais estimadores. Portanto, o valor ideal seria n_estimators=10.\n",
    "\n",
    "A seguir, vamos treinar o modelo com os valores ideais dos hiperparâmetros e salvar o resultado contento as intruções para aplicação do modelo a novos dados em um arquivo .joblib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar Modelo Selecionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                              ('model', ensemble.GradientBoostingClassifier(n_estimators=10))])\n",
    "my_pipeline.fit(X_train, y_train) \n",
    "dump(my_pipeline, './modelo_selecionado.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma estimativa de quão bem o modelo preditivo irá performar diante de novos dados, independentes daqueles utilizados para treinamento, é calculada atráves da aplicação do modelo aos dados de teste.\n",
    "\n",
    "Diante de um problema de classificação as previsões se referem à probabiblidade da observação pertencer à classe positiva, que no caso é o cliente em default. Podemos escolher diversos pontos de corte entre 0 e 1 para decidir quais clientes serão previstos como default (prob > ponto de corte) e quais serão previstos como ok (prob < ponto de corte).\n",
    "\n",
    "Dado que há uma expectativa da área de negócio em identificar ao menos 70% dos clientes que entrarão em default, vamos ajustar o ponto de corte para que esse percentual seja atingido. Porém precisamos avaliar se esse ponto de corte não impactará em muitos FP, clientes previstos como default e que não se tornaram inadimplentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_ponto_corte = 0.40\n",
    "probs = my_pipeline.predict_proba(X_test)[:,1]\n",
    "ponto_corte = np.quantile(probs, 1-pct_ponto_corte)\n",
    "VN, FP, FN, VP = confusion_matrix(y_test, (probs>ponto_corte).astype('int')).ravel()*100/len(y_test)\n",
    "print('Matriz de Confusão: \\n', [VP, FN], '\\n', [FP, VN])\n",
    "print('')\n",
    "print('Acurácia:', round(accuracy_score(y_test, (probs>ponto_corte).astype('int')),2))\n",
    "print('Recall:', round(recall_score(y_test, (probs>ponto_corte).astype('int')),2))\n",
    "print('Precisão:', round(precision_score(y_test, (probs>ponto_corte).astype('int')),2))\n",
    "print('')\n",
    "print('Ponde de Corte:', round(ponto_corte,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão:\n",
    "\n",
    "Para atingir a métrica de sucesso de identificar 70% dos clientes inadimplentes o modelo indica 40% do clientes como potenciais inadimplentes. Para isso, a taxa de falsos positivos, cliente previstos como inadimplentes que honraram ses compromissos no mÊs seguinte, fica em torno de 25%, o que pode ser considerado um valor alto pela área de negócio e representar perdas de oportunidades devido a ter mais cautela em negócios com esses clientes.\n",
    "\n",
    "Portanto, pode ser necessário mais uma iteração de levantamento de dados e refinamento do modelo para alcançar uma performance melhor do que obtida até o momento.\n",
    "\n",
    "Caso esse modelo seja aprovado, Ao aplicar o modelo e obter as previsões, o ponto de corte ideal dos scores para identificar clientes que se tornaram inadimplentes será considerar aqueles com score maior que 0.19. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e pré-visualização dos novos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = pd.read_csv('./UCI_Credit_Card_novo.csv', sep=',', decimal='.')\n",
    "dfnew.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que para os novos dados não temos a coluna da variável target, pois não temos essa informação ainda. Por isso, vamos aplicar o modelo treinado para fazer essa previsão.\n",
    "\n",
    "Observação: as alterações feitas nos dados antes do pré-processamento precisam ser replicadas aos novos dados. Neste caso, a única alteração foi renomear a coluna PAY_0 para PAY_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = dfnew.rename(columns={'PAY_0': 'PAY_1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga do arquivo que contém o modelo preditivo e aplicação aos novos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = load('./modelo_selecionado.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset para receber dados escorados\n",
    "dfscr = dfnew[['ID']]\n",
    "\n",
    "# Coluna com as probabilidades calculados\n",
    "dfscr['probs'] = my_pipeline.predict_proba(dfnew)[:,1]\n",
    "\n",
    "# Coluna com as previsões a partir do ponto de corte definido\n",
    "dfscr['previsto'] = [1 if x>0.19 else 0 for x in dfscr['probs']]\n",
    "\n",
    "# Pré-visualizar dados escorados\n",
    "dfscr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acabou?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda não! Depois de colocar seu modelo em produção para gerar previsões e fornecer insumos para as tomadas de decisão, é preciso acompanhar e monitorar a performance do modelo! \n",
    "\n",
    "No caso em estudo, no mês seguinte será possível observar quais clientes realmente entraram em default. É preciso deixar uma rotina de monitoramento que compare os valores previstos pelo modelo com os valores observados após o período de performance da variável target. Dessa forma, será possível acompanhar a performance do modelo ao longo do tempo e identificar quando a qualidade das previsões começa a ficar degradada. \n",
    "\n",
    "Nesse momento, é hora de pensar em revisitar o modelo novamente. A solução pode ser recalibrar o modelo com dados mais recentes, ou fazer um novo modelo, caso haja necessidade de levantar novas variáveis ou alterar a estrutura do modelo. Também há possibilidade de colocar em produção modelos de machine learning que já preveem a recalibragem automática ao longo do tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agora sim, acabou !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
